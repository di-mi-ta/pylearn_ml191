{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20cGZlV1WPT9"
   },
   "source": [
    "## Check GPU\n",
    "Chose Runtime -> Reset all runtime to get GPU NVIDIA Tesla P100 if provided GPU is not P100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "my5ZNBiJONhz",
    "outputId": "1ca86a88-4d5c-4cf2-d399-b58617089a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 16 15:00:32 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.44       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y80qGnOqIKg9"
   },
   "source": [
    "## Mount Drive to VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Hiwdcv9u94Bx",
    "outputId": "87c6198e-ef89-443d-8c9c-14d89cefee12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATA_PATH = '/content/drive/My Drive/Thesis/Code/ML/mnist_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDgAFVOvIPjd"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjGK4lDxQ_RS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9Y5zMnjISjd"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6n5YOFlbqQQe"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor(),  \n",
    "     transforms.Normalize((0.1307,), (0.3081,))                    \n",
    "])\n",
    "\n",
    "# Data \n",
    "data = datasets.MNIST(root=\"./data/\", \n",
    "                         train=True, \n",
    "                         transform=transform, \n",
    "                         download=True)\n",
    "\n",
    "# Get test set\n",
    "test_set = datasets.MNIST('../mnist_data', \n",
    "                          download=True, \n",
    "                          train=False,\n",
    "                          transform=transform)\n",
    "\n",
    "# Split data to train_set, dev_set\n",
    "train_set, val_set = torch.utils.data.random_split(data, lengths=[50000, 10000])\n",
    "\n",
    "# Train_loader\n",
    "train_loader = DataLoader(train_set, \n",
    "                          batch_size=64, \n",
    "                          shuffle=True,\n",
    "                          pin_memory=True)\n",
    "# Dev_loader\n",
    "val_loader = DataLoader(val_set, \n",
    "                        batch_size=64, \n",
    "                        shuffle=False, \n",
    "                        pin_memory=True)\n",
    "\n",
    "# Test Loader\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQhdeAHuqLvp"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGkaHNo0dhgn"
   },
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv2_drop = nn.Dropout2d(p=0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc1_relu = nn.ReLU()\n",
    "        self.fc1_drop = nn.Dropout2d(p=0.5)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x.view(-1, 320)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_relu(x)\n",
    "        x = self.fc1_drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "fVFUEEGaIviX",
    "outputId": "2701b31c-c030-4c75-aa7b-875c4b1c9a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu2): ReLU()\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc1_relu): ReLU()\n",
      "  (fc1_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MNISTNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8bMiCXOsdkpu"
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=3e-4,\n",
    "                            betas=[0.5, 0.999])\n",
    "\n",
    "# Using cuda\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jVMD5mcOpZu"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "id": "YYP36U5idsJ6",
    "outputId": "bfca1aea-4b33-4d01-d406-f00c29c97d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.2748, val_loss: 0.1023\n",
      "Epoch 2, train_loss: 0.2379, val_loss: 0.0887\n",
      "Epoch 3, train_loss: 0.2167, val_loss: 0.0819\n",
      "Epoch 4, train_loss: 0.2005, val_loss: 0.0742\n",
      "Epoch 5, train_loss: 0.1866, val_loss: 0.0710\n",
      "Epoch 6, train_loss: 0.1839, val_loss: 0.0679\n",
      "Epoch 7, train_loss: 0.1763, val_loss: 0.0628\n",
      "Epoch 8, train_loss: 0.1678, val_loss: 0.0634\n",
      "Epoch 9, train_loss: 0.1612, val_loss: 0.0622\n",
      "Epoch 10, train_loss: 0.1579, val_loss: 0.0622\n",
      "Epoch 11, train_loss: 0.1485, val_loss: 0.0588\n",
      "Epoch 12, train_loss: 0.1475, val_loss: 0.0568\n",
      "Epoch 13, train_loss: 0.1451, val_loss: 0.0566\n",
      "Epoch 14, train_loss: 0.1442, val_loss: 0.0569\n",
      "Epoch 15, train_loss: 0.1396, val_loss: 0.0531\n",
      "Epoch 16, train_loss: 0.1356, val_loss: 0.0564\n",
      "Epoch 17, train_loss: 0.1318, val_loss: 0.0550\n",
      "Epoch 18, train_loss: 0.1333, val_loss: 0.0529\n",
      "Epoch 19, train_loss: 0.1294, val_loss: 0.0519\n",
      "Epoch 20, train_loss: 0.1270, val_loss: 0.0525\n",
      "Epoch 21, train_loss: 0.1243, val_loss: 0.0498\n",
      "Epoch 22, train_loss: 0.1245, val_loss: 0.0509\n",
      "Epoch 23, train_loss: 0.1229, val_loss: 0.0495\n",
      "Epoch 24, train_loss: 0.1229, val_loss: 0.0483\n",
      "Epoch 25, train_loss: 0.1183, val_loss: 0.0508\n",
      "Epoch 26, train_loss: 0.1215, val_loss: 0.0493\n",
      "Epoch 27, train_loss: 0.1160, val_loss: 0.0490\n",
      "Epoch 28, train_loss: 0.1136, val_loss: 0.0475\n",
      "Epoch 29, train_loss: 0.1145, val_loss: 0.0510\n",
      "Epoch 30, train_loss: 0.1129, val_loss: 0.0478\n"
     ]
    }
   ],
   "source": [
    "# Some setting\n",
    "num_epochs = 30\n",
    "best_model_path = './best_model.data'\n",
    "best_val_loss = float(\"inf\") \n",
    "step = 0\n",
    "print_every = 100\n",
    "num_batch_train = len(train_loader)\n",
    "num_batch_val = len(val_loader)\n",
    "\n",
    "# Training\n",
    "for epoch in range(0, num_epochs):\n",
    "    # Set mode train for using dropout\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_idx, (batch_data, batch_label) in enumerate(train_loader):\n",
    "      # Move to GPU if device = \"cuda\"\n",
    "      batch_data = batch_data.to(device)\n",
    "      batch_label = batch_label.to(device)\n",
    "\n",
    "      step += 1\n",
    "      # Forward phase \n",
    "      out = model(batch_data)\n",
    "\n",
    "      # Calculate loss \n",
    "      loss = criterion(out, batch_label)\n",
    "\n",
    "      # Backward and update parameters\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.data\n",
    "    train_loss = running_loss / num_batch_train\n",
    "    \n",
    "    # Set model eval \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for batch_idx, (batch_data, batch_label) in enumerate(val_loader):\n",
    "      # Move to GPU if device = \"cuda\"\n",
    "      batch_data = batch_data.to(device)\n",
    "      batch_label = batch_label.to(device)\n",
    "\n",
    "      # Forward\n",
    "      out = model(batch_data)\n",
    "\n",
    "      # Calculate loss\n",
    "      v_loss = criterion(out, batch_label)\n",
    "      val_loss += v_loss.data \n",
    "    val_loss /= num_batch_val \n",
    "\n",
    "    # Save model if it better than current best model\n",
    "    if val_loss < best_val_loss:\n",
    "      best_val_loss = val_loss\n",
    "      torch.save(model.state_dict(), best_model_path)\n",
    "    \n",
    "    # Log\n",
    "    print(\"Epoch {}, train_loss: {:0.4f}, val_loss: {:0.4f}\".format(epoch + 1, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gP6SbCTwInIO",
    "outputId": "0c8807be-f912-4e96-a3f2-6b29248595d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZFo74OHKXn3"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "  predicts = []\n",
    "  targets = [] \n",
    "  for batch_idx, (batch_data, batch_label) in enumerate(dataloader):\n",
    "    batch_data = batch_data.to(device)\n",
    "    batch_label = batch_label.to(device)\n",
    "\n",
    "    out = model(batch_data)\n",
    "    out = F.softmax(out)\n",
    "    out = torch.argmax(out, dim=1).detach()\n",
    "    predicts.append(out)\n",
    "    targets.append(batch_label)\n",
    "  predicts = torch.cat(predicts, dim=0).cpu().numpy()\n",
    "  targets = torch.cat(targets, dim=0).cpu().numpy()\n",
    "  return predicts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "cwyRBHA8KKLA",
    "outputId": "5c4cdf73-f7a3-4a36-faae-3f98ba2346d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions for test set using API in PyTorch\n",
    "predicts, targets = predict(model, test_loader, device)\n",
    "print(classification_report(targets, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RlNbid94JK8"
   },
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfwmyaxhNpEe"
   },
   "outputs": [],
   "source": [
    "class FeaturesExtractor(nn.Module):\n",
    "  def __init__(self, model):\n",
    "    super(FeaturesExtractor, self).__init__()\n",
    "    self.conv1 = model.conv1\n",
    "    self.pool1 = model.pool1\n",
    "    self.relu1 = model.relu1\n",
    "    self.conv2 = model.conv2\n",
    "    self.pool2 = model.pool2\n",
    "    self.relu2 = model.relu2\n",
    "    self.conv2_drop = model.conv2_drop \n",
    "    self.fc1 = model.fc1\n",
    "    self.fc1_relu = model.fc1_relu\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.pool1(x)\n",
    "    x = self.relu1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.pool2(x)\n",
    "    x = self.relu2(x)\n",
    "    x = self.conv2_drop(x)\n",
    "    x = x.view(-1, 320)\n",
    "    x = self.fc1(x)\n",
    "    out = self.fc1_relu(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "5V51LfBXM3vH",
    "outputId": "836dc0d3-41c9-4754-f8b9-da88499ec56a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesExtractor(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): ReLU()\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc1_relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = FeaturesExtractor(model)\n",
    "\n",
    "# Set mode eval to get features\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMoLJLG_I-DN"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BS-rwjbWRRvR"
   },
   "outputs": [],
   "source": [
    "def extract_features(model, dataloader):\n",
    "  features_total = []\n",
    "  target = []\n",
    "  for batch_idx, (batch_data, batch_label) in enumerate(dataloader):\n",
    "    batch_data = batch_data.to(device)\n",
    "    batch_label = batch_label.to(device)\n",
    "\n",
    "    features = feature_extractor(batch_data)\n",
    "    target.append(batch_label)\n",
    "    features_total.append(features)\n",
    "  \n",
    "  features = torch.cat(features_total, dim=0).cpu().detach().numpy()\n",
    "  target = torch.cat(target, dim=0).cpu().detach().numpy()\n",
    "  return features, target\n",
    "\n",
    "##############\n",
    "def get_plain_data(loader):\n",
    "  features_total = []\n",
    "  target = []\n",
    "  for batch_idx, (batch_data, batch_label) in enumerate(loader):\n",
    "    batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "    batch_label = batch_label.view(batch_label.size(0), -1)\n",
    "    target.append(batch_label)\n",
    "    features_total.append(batch_data)\n",
    "  \n",
    "  features = torch.cat(features_total, dim=0).cpu().detach().numpy()\n",
    "  target = torch.cat(target, dim=0).cpu().detach().numpy()\n",
    "  return features, target\n",
    "\n",
    "##############\n",
    "def save_feature_to_csv(features, target, filename):\n",
    "  features_dim = features.shape[1]\n",
    "  df = pd.DataFrame(columns = [\"f_{}\".format(i) for i in range(features_dim)] + [\"label\"])\n",
    "  for i in range(features_dim):\n",
    "    df[\"f_{}\".format(i)] = features[:, i]\n",
    "  df[\"label\"] = target\n",
    "  df.to_csv(filename, index=False, header=False)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nP5hi1aJDUh"
   },
   "source": [
    "## Transform data to features for using with Softmax Regression in pylearn_ml191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INd4yWIb8ZIk"
   },
   "outputs": [],
   "source": [
    "train_plain_features, train_plain_target = get_plain_data(train_loader)\n",
    "val_plain_features, val_plain_target = get_plain_data(val_loader)\n",
    "test_plain_features, test_plain_target = get_plain_data(test_loader)\n",
    "\n",
    "df_train_plain = save_feature_to_csv(train_plain_features, \n",
    "                                     train_plain_target, \n",
    "                                     os.path.join(DATA_PATH, \"train_set_plain.csv\"))\n",
    "\n",
    "df_val_plain = save_feature_to_csv(val_plain_features, \n",
    "                                   val_plain_target, \n",
    "                                   os.path.join(DATA_PATH, \"val_set_plain.csv\"))\n",
    "\n",
    "df_test_plain = save_feature_to_csv(test_plain_features, \n",
    "                                    test_plain_target, \n",
    "                                    os.path.join(DATA_PATH, \"test_set_plain.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udyRVz6QNPG7"
   },
   "outputs": [],
   "source": [
    "train_features, train_target = extract_features(feature_extractor, train_loader)\n",
    "train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "train_target = train_target.reshape(train_target.shape[0], -1)\n",
    "\n",
    "val_features, val_target = extract_features(feature_extractor, val_loader)\n",
    "val_features = val_features.reshape(val_features.shape[0], -1)\n",
    "val_target = val_target.reshape(val_target.shape[0], -1)\n",
    "\n",
    "test_features, test_target = extract_features(feature_extractor, test_loader)\n",
    "test_features = test_features.reshape(test_features.shape[0], -1)\n",
    "test_target = test_target.reshape(test_target.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LIMVUguv2Vy3"
   },
   "outputs": [],
   "source": [
    "df_train = save_feature_to_csv(train_features, \n",
    "                               train_target, \n",
    "                               os.path.join(DATA_PATH, \"train_set_extracted.csv\"))\n",
    "\n",
    "df_val = save_feature_to_csv(val_features, \n",
    "                             val_target, \n",
    "                             os.path.join(DATA_PATH, \"val_set_extracted.csv\"))\n",
    "\n",
    "df_test = save_feature_to_csv(test_features, \n",
    "                               test_target, \n",
    "                               os.path.join(DATA_PATH, \"test_set_extracted.csv\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "20cGZlV1WPT9",
    "y80qGnOqIKg9",
    "wDgAFVOvIPjd",
    "y9Y5zMnjISjd",
    "3VrrrDkYURyz",
    "lQhdeAHuqLvp",
    "7jVMD5mcOpZu",
    "4RlNbid94JK8",
    "zMoLJLG_I-DN",
    "6nP5hi1aJDUh"
   ],
   "name": "mnist-feature-extraction-pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}