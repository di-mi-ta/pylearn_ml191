{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# Import from sklearn lib \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Import from pylearn_ml191 lib \n",
    "from pylearn_ml191.linear_regression import SoftmaxRegression\n",
    "from pylearn_ml191.dimentional_reduction import PCA\n",
    "\n",
    "# Fix random seed\n",
    "np.random.seed(21)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_train_set = pd.read_csv(\"./mnist_data/train_set_plain.csv\", header=None)\n",
    "plain_val_set = pd.read_csv(\"./mnist_data/val_set_plain.csv\", header=None)\n",
    "plain_test_set = pd.read_csv(\"./mnist_data/val_set_plain.csv\", header=None)\n",
    "\n",
    "extracted_train_set = pd.read_csv(\"./mnist_data/train_set_extracted.csv\", header=None)\n",
    "extracted_val_set = pd.read_csv(\"./mnist_data/val_set_extracted.csv\", header=None)\n",
    "extracted_test_set = pd.read_csv(\"./mnist_data/val_set_extracted.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_train_set = plain_train_set.values\n",
    "plain_val_set = plain_val_set.values \n",
    "plain_test_set = plain_test_set.values\n",
    "\n",
    "extracted_train_set = extracted_train_set.values \n",
    "extracted_val_set = extracted_val_set.values \n",
    "extracted_test_set = extracted_test_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number original features:  784\n",
      "Number extracted features by CNN:  50\n"
     ]
    }
   ],
   "source": [
    "num_features_plain = plain_train_set.shape[1] - 1\n",
    "num_features_extracted = extracted_train_set.shape[1] - 1 \n",
    "print(\"Number original features: \", num_features_plain)\n",
    "print(\"Number extracted features by CNN: \", num_features_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_train_features = plain_train_set[:, :num_features_plain]\n",
    "plain_train_target = plain_train_set[:, num_features_plain]\n",
    "\n",
    "plain_val_features = plain_val_set[:, :num_features_plain]\n",
    "plain_val_target = plain_val_set[:, num_features_plain]\n",
    "\n",
    "plain_test_features = plain_test_set[:, :num_features_plain]\n",
    "plain_test_target = plain_test_set[:, num_features_plain]\n",
    "\n",
    "extracted_train_features = extracted_train_set[:, :num_features_extracted]\n",
    "extracted_train_target = extracted_train_set[:, num_features_extracted]\n",
    "extracted_val_features = extracted_val_set[:, :num_features_extracted]\n",
    "extracted_val_target = extracted_val_set[:, num_features_extracted]\n",
    "extracted_test_features = extracted_test_set[:, :num_features_extracted]\n",
    "extracted_test_target = extracted_test_set[:, num_features_extracted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain data set:\n",
      "========================\n",
      "Train set: \n",
      "(50000, 784)\n",
      "(50000,)\n",
      "------------------------\n",
      "Dev/Val set: \n",
      "(10000, 784)\n",
      "(10000,)\n",
      "------------------------\n",
      "Test set: \n",
      "(10000, 784)\n",
      "(10000,)\n",
      "\n",
      "\n",
      "Extracted data set:\n",
      "========================\n",
      "Train set: \n",
      "(50000, 50)\n",
      "(50000,)\n",
      "------------------------\n",
      "Dev/Val set: \n",
      "(10000, 50)\n",
      "(10000,)\n",
      "------------------------\n",
      "Test set: \n",
      "(10000, 50)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Plain data set:\")\n",
    "print(\"========================\")\n",
    "print(\"Train set: \")\n",
    "print(plain_train_features.shape)\n",
    "print(plain_train_target.shape)\n",
    "print(\"------------------------\")\n",
    "print(\"Dev/Val set: \")\n",
    "print(plain_val_features.shape)\n",
    "print(plain_val_target.shape)\n",
    "print(\"------------------------\")\n",
    "print(\"Test set: \")\n",
    "print(plain_test_features.shape)\n",
    "print(plain_test_target.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Extracted data set:\")\n",
    "print(\"========================\")\n",
    "print(\"Train set: \")\n",
    "print(extracted_train_features.shape)\n",
    "print(extracted_train_target.shape)\n",
    "print(\"------------------------\")\n",
    "print(\"Dev/Val set: \")\n",
    "print(extracted_val_features.shape)\n",
    "print(extracted_val_target.shape)\n",
    "print(\"------------------------\")\n",
    "print(\"Test set: \")\n",
    "print(extracted_test_features.shape)\n",
    "print(extracted_test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on plain data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step: 200] Train-loss: 1.222657546183608, Val-loss: 1.2340570294907685\n",
      "[Step: 400] Train-loss: 1.386364921940733, Val-loss: 0.9654684669068513\n",
      "[Step: 600] Train-loss: 0.3025618962926608, Val-loss: 0.8825955847263796\n",
      "[Step: 800] Train-loss: 0.7755798668761295, Val-loss: 0.845781594316727\n",
      "[Step: 1000] Train-loss: 0.48550257053887996, Val-loss: 0.8123020901646454\n",
      "[Step: 1200] Train-loss: 0.7509877575016007, Val-loss: 0.7683984914996647\n",
      "[Step: 1400] Train-loss: 0.7192505239575575, Val-loss: 0.7458643381243852\n",
      "[Step: 1600] Train-loss: 0.8960887533188935, Val-loss: 0.7532096705543584\n",
      "[Step: 1800] Train-loss: 0.7474224004255632, Val-loss: 0.776563115729936\n",
      "[Step: 2000] Train-loss: 0.7596355536195363, Val-loss: 0.703642314517599\n",
      "[Step: 2200] Train-loss: 0.4560685727878856, Val-loss: 0.6668540436193755\n",
      "[Step: 2400] Train-loss: 1.0406376094456204, Val-loss: 0.6554108398819152\n",
      "[Step: 2600] Train-loss: 0.6933733690374054, Val-loss: 0.6338908414092711\n",
      "[Step: 2800] Train-loss: 0.4907242358535622, Val-loss: 0.6659125539773302\n",
      "[Step: 3000] Train-loss: 0.4853623716064055, Val-loss: 0.6831228405356986\n",
      "[Step: 3200] Train-loss: 0.05540024215096716, Val-loss: 0.6116723377557297\n",
      "[Step: 3400] Train-loss: 0.28234199055317655, Val-loss: 0.6046359108287799\n",
      "[Step: 3600] Train-loss: 0.5021498969119491, Val-loss: 0.5956650389088605\n",
      "[Step: 3800] Train-loss: 0.7444894884750959, Val-loss: 0.6117249361388729\n",
      "[Step: 4000] Train-loss: 0.5636386987482007, Val-loss: 0.6079712155971669\n",
      "[Step: 4200] Train-loss: 0.16665366040120747, Val-loss: 0.576113935182954\n",
      "[Step: 4400] Train-loss: 0.6047740225793857, Val-loss: 0.6023036480426455\n",
      "[Step: 4600] Train-loss: 0.6921320708009931, Val-loss: 0.5998283839968876\n",
      "[Step: 4800] Train-loss: 0.4990545137563122, Val-loss: 0.5771103779379505\n",
      "[Step: 5000] Train-loss: 0.7576803718406737, Val-loss: 0.5650053182273979\n",
      "[Step: 5200] Train-loss: 0.2545290737311645, Val-loss: 0.578906726087254\n",
      "[Step: 5400] Train-loss: 0.5626602126978802, Val-loss: 0.5618423997849645\n",
      "[Step: 5600] Train-loss: 0.6109779230331603, Val-loss: 0.5718913342487257\n",
      "[Step: 5800] Train-loss: 0.4711152574331329, Val-loss: 0.5612171951530125\n",
      "[Step: 6000] Train-loss: 0.8209713010784974, Val-loss: 0.5591491329466205\n",
      "[Step: 6200] Train-loss: 0.6325259181684891, Val-loss: 0.540309831749578\n",
      "[Step: 6400] Train-loss: 0.666950536792231, Val-loss: 0.5426198610523156\n",
      "[Step: 6600] Train-loss: 0.09392275821101226, Val-loss: 0.5428431542311373\n",
      "[Step: 6800] Train-loss: 0.41535386579003575, Val-loss: 0.5331575167239444\n",
      "[Step: 7000] Train-loss: 0.8845323043914688, Val-loss: 0.5339389217089296\n",
      "[Step: 7200] Train-loss: 0.31237748897340045, Val-loss: 0.531854683792678\n",
      "[Step: 7400] Train-loss: 0.32987693140541274, Val-loss: 0.53459999423712\n",
      "[Step: 7600] Train-loss: 0.18780501552774298, Val-loss: 0.5286828159899788\n",
      "[Step: 7800] Train-loss: 0.3897244023032179, Val-loss: 0.5339033043366955\n",
      "[Step: 8000] Train-loss: 0.6862223785262662, Val-loss: 0.5312952071683325\n",
      "[Step: 8200] Train-loss: 0.2716925005635771, Val-loss: 0.5290005729591073\n",
      "[Step: 8400] Train-loss: 0.5188166973668158, Val-loss: 0.5237182500132073\n",
      "[Step: 8600] Train-loss: 0.6633901749337464, Val-loss: 0.5194092066091993\n",
      "[Step: 8800] Train-loss: 0.6485585801465477, Val-loss: 0.5266427873065459\n",
      "[Step: 9000] Train-loss: 0.516827668402823, Val-loss: 0.5226287012859495\n",
      "[Step: 9200] Train-loss: 0.25109536190952775, Val-loss: 0.5138604045262989\n",
      "[Step: 9400] Train-loss: 0.13355354669955655, Val-loss: 0.5121226747832115\n",
      "[Step: 9600] Train-loss: 0.6231355026701428, Val-loss: 0.5072918435064658\n",
      "[Step: 9800] Train-loss: 0.3797102516566795, Val-loss: 0.5109366084899614\n",
      "[Step: 10000] Train-loss: 0.29471119024124875, Val-loss: 0.5059227437447361\n",
      "Stop training at step: 10000, best val loss: 0.5059227437447361\n",
      "CPU times: user 21.1 s, sys: 3.48 s, total: 24.6 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = SoftmaxRegression(num_classes=10, use_features_extractor=False)\n",
    "history = classifier.fit(plain_train_features, plain_train_target, \n",
    "                         plain_val_features, plain_val_target,\n",
    "                         max_steps=10000,\n",
    "                         step_to_lr_decay=3000,\n",
    "                         lr_decay=0.5,\n",
    "                         batch_size=64, \n",
    "                         lr=4e-3, \n",
    "                         min_W_diff=1e-5,\n",
    "                         verbose=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95       987\n",
      "         1.0       0.94      0.96      0.95      1155\n",
      "         2.0       0.87      0.88      0.87       972\n",
      "         3.0       0.89      0.85      0.87      1027\n",
      "         4.0       0.91      0.89      0.90      1012\n",
      "         5.0       0.84      0.84      0.84       863\n",
      "         6.0       0.94      0.94      0.94      1019\n",
      "         7.0       0.91      0.91      0.91       999\n",
      "         8.0       0.84      0.83      0.83       977\n",
      "         9.0       0.85      0.87      0.86       989\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.90      0.90      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.eval(plain_test_features, categorical=True)\n",
    "print(classification_report(plain_test_target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on features extracted from pretrained CNN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step: 10] Train-loss: 2.431145220776398, Val-loss: 1.9128000192581567\n",
      "[Step: 20] Train-loss: 0.33394817904258356, Val-loss: 0.38804332603425923\n",
      "[Step: 30] Train-loss: 0.29347505734305235, Val-loss: 0.31534853296741905\n",
      "[Step: 40] Train-loss: 0.4267453791784826, Val-loss: 0.3014880467849264\n",
      "[Step: 50] Train-loss: 0.20049361397134605, Val-loss: 0.23789017839237156\n",
      "[Step: 60] Train-loss: 0.1842431445806834, Val-loss: 0.19937038256606318\n",
      "[Step: 70] Train-loss: 0.22556401885167557, Val-loss: 0.182598456381533\n",
      "[Step: 80] Train-loss: 0.274340455274613, Val-loss: 0.17802297322595517\n",
      "[Step: 90] Train-loss: 0.06415024941631156, Val-loss: 0.17159039247465468\n",
      "[Step: 100] Train-loss: 0.17377152409144278, Val-loss: 0.1617344358056598\n",
      "[Step: 110] Train-loss: 0.47413212547545613, Val-loss: 0.15059174531022215\n",
      "[Step: 120] Train-loss: 0.4699488885223151, Val-loss: 0.15215742033897312\n",
      "[Step: 130] Train-loss: 0.3110670438425659, Val-loss: 0.14325265468425377\n",
      "[Step: 140] Train-loss: 0.2820642077628989, Val-loss: 0.14286710607105102\n",
      "[Step: 150] Train-loss: 0.07032648563663702, Val-loss: 0.1432317494266042\n",
      "[Step: 160] Train-loss: 0.09025290590825927, Val-loss: 0.13672403911981132\n",
      "[Step: 170] Train-loss: -9.987728112698562e-05, Val-loss: 0.12945744035461101\n",
      "Stop training at step: 170, best val loss: 0.12945744035461101\n",
      "CPU times: user 526 ms, sys: 23.5 ms, total: 550 ms\n",
      "Wall time: 320 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = SoftmaxRegression(num_classes=10, use_features_extractor=False)\n",
    "history = classifier.fit(extracted_train_features, extracted_train_target, \n",
    "                         extracted_val_features, extracted_val_target, \n",
    "                         max_steps=10000,\n",
    "                         step_to_lr_decay=3000,\n",
    "                         lr_decay=0.5,\n",
    "                         batch_size=64, \n",
    "                         lr=4e-3, \n",
    "                         min_W_diff=1e-5,\n",
    "                         verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.99       987\n",
      "         1.0       0.98      0.97      0.98      1155\n",
      "         2.0       0.96      0.98      0.97       972\n",
      "         3.0       0.98      0.97      0.98      1027\n",
      "         4.0       0.98      0.98      0.98      1012\n",
      "         5.0       0.97      0.98      0.98       863\n",
      "         6.0       0.98      0.99      0.98      1019\n",
      "         7.0       0.96      0.98      0.97       999\n",
      "         8.0       0.98      0.96      0.97       977\n",
      "         9.0       0.97      0.97      0.97       989\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.eval(extracted_test_features, categorical=True)\n",
    "print(classification_report(extracted_test_target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimentional Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.92 s, sys: 424 ms, total: 3.35 s\n",
      "Wall time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=100)\n",
    "plain_train_features_new = pca.fit_transform(plain_train_features)\n",
    "plain_val_features_new = pca.transform(plain_val_features)\n",
    "plain_test_features_new = pca.transform(plain_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step: 200] Train-loss: (0.4676094858030694-0j), Val-loss: (0.7713511357410786+0j)\n",
      "[Step: 400] Train-loss: (0.626555268064406-0j), Val-loss: (0.5968683793234283+0j)\n",
      "[Step: 600] Train-loss: (0.7050300318266907-0j), Val-loss: (0.508990413939314+0j)\n",
      "[Step: 800] Train-loss: (0.361955468353638-0j), Val-loss: (0.4460728663878713+0j)\n",
      "[Step: 1000] Train-loss: (0.5230690161617236-0j), Val-loss: (0.44099704105884857+0j)\n",
      "[Step: 1200] Train-loss: (0.4438966759612844-0j), Val-loss: (0.4024341596359742+0j)\n",
      "[Step: 1400] Train-loss: (0.4666239023659501-0j), Val-loss: (0.38476903264658263+0j)\n",
      "[Step: 1600] Train-loss: (0.39903517228672936-0j), Val-loss: (0.37861386610691705+0j)\n",
      "[Step: 1800] Train-loss: (0.4146599616393418-0j), Val-loss: (0.37313172543151946+0j)\n",
      "[Step: 2000] Train-loss: (0.3333583089214729-0j), Val-loss: (0.3741742390294824+0j)\n",
      "[Step: 2200] Train-loss: (0.36241296991031174-0j), Val-loss: (0.37780923889727575+0j)\n",
      "[Step: 2400] Train-loss: (0.3747339720222896-0j), Val-loss: (0.39356212798199286+0j)\n",
      "[Step: 2600] Train-loss: (0.3394714375501706-0j), Val-loss: (0.3888861808996338+0j)\n",
      "[Step: 2800] Train-loss: (0.5423898864635829-0j), Val-loss: (0.38723729434633025+0j)\n",
      "[Step: 3000] Train-loss: (0.4157404932924205-0j), Val-loss: (0.38665030286985447+0j)\n",
      "[Step: 3200] Train-loss: (0.24398230124440842-0j), Val-loss: (0.34049086743895723+0j)\n",
      "[Step: 3400] Train-loss: (0.20117875679128866-0j), Val-loss: (0.32688894481925784+0j)\n",
      "[Step: 3600] Train-loss: (0.3737247953981011-0j), Val-loss: (0.3416176351814151+0j)\n",
      "[Step: 3800] Train-loss: (0.19702527127506114-0j), Val-loss: (0.3295341636981425+0j)\n",
      "[Step: 4000] Train-loss: (0.2986631307544022-0j), Val-loss: (0.3335490158808666+0j)\n",
      "[Step: 4200] Train-loss: (0.11664160589058054-0j), Val-loss: (0.3316438272442726+0j)\n",
      "[Step: 4400] Train-loss: (0.3211935318756628-0j), Val-loss: (0.3390280622305383+0j)\n",
      "[Step: 4600] Train-loss: (0.41921474360730115-0j), Val-loss: (0.3266314285664804+0j)\n",
      "[Step: 4800] Train-loss: (0.23879552317084551-0j), Val-loss: (0.33128736003576037+0j)\n",
      "[Step: 5000] Train-loss: (0.38873762131305534-0j), Val-loss: (0.33579769278956384+0j)\n",
      "[Step: 5200] Train-loss: (0.23808356142622905-0j), Val-loss: (0.3227095368870292+0j)\n",
      "[Step: 5400] Train-loss: (0.2397715159033778-0j), Val-loss: (0.34415069179575325+0j)\n",
      "[Step: 5600] Train-loss: (0.3695735742530713-0j), Val-loss: (0.33326851153051645+0j)\n",
      "[Step: 5800] Train-loss: (0.273698478319011-0j), Val-loss: (0.3292785518815743+0j)\n",
      "[Step: 6000] Train-loss: (0.5026117294760761-0j), Val-loss: (0.33099218942995556+0j)\n",
      "[Step: 6200] Train-loss: (0.37643908843921015-0j), Val-loss: (0.3177852366099976+0j)\n",
      "[Step: 6400] Train-loss: (0.24210381210463625-0j), Val-loss: (0.3141540709619695+0j)\n",
      "[Step: 6600] Train-loss: (0.24996284855582554-0j), Val-loss: (0.30794545495630177+0j)\n",
      "[Step: 6800] Train-loss: (0.24197579052129897-0j), Val-loss: (0.3096441400269996+0j)\n",
      "[Step: 7000] Train-loss: (0.49209745588133225-0j), Val-loss: (0.3133488256933678+0j)\n",
      "[Step: 7200] Train-loss: (0.30814890448770904-0j), Val-loss: (0.3150149395433617+0j)\n",
      "[Step: 7400] Train-loss: (0.3207184205499721-0j), Val-loss: (0.3105593662546137+0j)\n",
      "[Step: 7600] Train-loss: (0.22210076876072982-0j), Val-loss: (0.31645253685887254+0j)\n",
      "[Step: 7800] Train-loss: (0.25716887101876956-0j), Val-loss: (0.31399098683669235+0j)\n",
      "[Step: 8000] Train-loss: (0.4004032991590396-0j), Val-loss: (0.31102489257850435+0j)\n",
      "[Step: 8200] Train-loss: (0.26484510577095144-0j), Val-loss: (0.31607692193084225+0j)\n",
      "[Step: 8400] Train-loss: (0.18634972024514324-0j), Val-loss: (0.3165802249933968+0j)\n",
      "[Step: 8600] Train-loss: (0.23729269189223737-0j), Val-loss: (0.3128188087969463+0j)\n",
      "[Step: 8800] Train-loss: (0.2991712127624682-0j), Val-loss: (0.3103194925219408+0j)\n",
      "[Step: 9000] Train-loss: (0.3809832020339658-0j), Val-loss: (0.312443058904757+0j)\n",
      "[Step: 9200] Train-loss: (0.43714240649820674-0j), Val-loss: (0.30758068703556096+0j)\n",
      "[Step: 9400] Train-loss: (0.21565388532331714-0j), Val-loss: (0.30754816889785114+0j)\n",
      "[Step: 9600] Train-loss: (0.34906770744983395-0j), Val-loss: (0.3047291279987066+0j)\n",
      "[Step: 9800] Train-loss: (0.2086382151974434-0j), Val-loss: (0.3052905867933629+0j)\n",
      "[Step: 10000] Train-loss: (0.4894100906557565-0j), Val-loss: (0.3087097528755692+0j)\n",
      "Stop training at step: 10000, best val loss: (0.3047291279987066+0j)\n",
      "CPU times: user 11.7 s, sys: 367 ms, total: 12.1 s\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "classifier = SoftmaxRegression(num_classes=10, use_features_extractor=False)\n",
    "history = classifier.fit(plain_train_features_new, plain_train_target, \n",
    "                         plain_val_features_new, plain_val_target, \n",
    "                         max_steps=10000,\n",
    "                         step_to_lr_decay=3000,\n",
    "                         lr_decay=0.5,\n",
    "                         batch_size=128, \n",
    "                         lr=4e-3, \n",
    "                         min_W_diff=1e-5,\n",
    "                         verbose=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96       987\n",
      "         1.0       0.93      0.97      0.95      1155\n",
      "         2.0       0.92      0.90      0.91       972\n",
      "         3.0       0.91      0.90      0.91      1027\n",
      "         4.0       0.91      0.93      0.92      1012\n",
      "         5.0       0.90      0.84      0.87       863\n",
      "         6.0       0.94      0.96      0.95      1019\n",
      "         7.0       0.92      0.94      0.93       999\n",
      "         8.0       0.88      0.84      0.86       977\n",
      "         9.0       0.89      0.89      0.89       989\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.91      0.91     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.eval(plain_test_features_new, categorical=True)\n",
    "print(classification_report(plain_test_target, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
